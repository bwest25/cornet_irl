{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle as p\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_NBP_RECORDS_FILENAME = \"saved/NBP_73812_records.p\"\n",
    "FINAL_EBP_RECORDS_FILENAME = \"saved/EBP_4612_records.p\"\n",
    "FINAL_FMP_RECORDS_FILENAME = \"saved/FMP_4612_records.p\"\n",
    "\n",
    "NBP_BATCH_SIZE = 8\n",
    "EBP_BATCH_SIZE = 128\n",
    "FMP_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_records(records_filename, batch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        records_filename (string): name of file that has records\n",
    "        batch_size (int): batch size per training step\n",
    "    \n",
    "    Returns:\n",
    "        training_points (numpy array): array of the training points that saves occurred at\n",
    "        val_class_losses (numpy array): array of the validation class losses at each save\n",
    "        val_normal_losses (numpy array): array of the validation normal losses at each save\n",
    "        training_class_losses (numpy array): array of the training class losses at each save\n",
    "        training_normal_losses (numpy array): array of the training normal losses at each save\n",
    "    \"\"\"\n",
    "    with open(records_filename, \"rb\") as f:\n",
    "        records = p.load(f)\n",
    "        \n",
    "    num_saved = len(records)\n",
    "    \n",
    "    training_points = np.zeros(num_saved, dtype=np.int)\n",
    "    val_class_losses = np.zeros(num_saved)\n",
    "    val_normal_losses = np.zeros(num_saved)\n",
    "    training_class_losses = np.zeros(num_saved)\n",
    "    training_normal_losses = np.zeros(num_saved)\n",
    "    \n",
    "    for i, record in enumerate(records):\n",
    "        training_points[i] = record[\"global_step\"] * batch_size\n",
    "        val_class_losses[i] = record[\"val_class_loss\"]\n",
    "        val_normal_losses[i] = record[\"val_normals_loss\"]\n",
    "        training_class_losses[i] = record[\"train_class_loss\"]\n",
    "        training_normal_losses[i] = record[\"train_normals_loss\"]\n",
    "        \n",
    "    return training_points, val_class_losses, val_normal_losses,\\\n",
    "        training_class_losses, training_normal_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile records for each training stage\n",
    "nbp_training_points, nbp_val_class_losses, nbp_val_normal_losses,\\\n",
    "    nbp_training_class_losses, nbp_training_normal_losses =\\\n",
    "        compile_records(FINAL_NBP_RECORDS_FILENAME, NBP_BATCH_SIZE)\n",
    "\n",
    "ebp_training_points, ebp_val_class_losses, ebp_val_normal_losses,\\\n",
    "    ebp_training_class_losses, ebp_training_normal_losses =\\\n",
    "        compile_records(FINAL_EBP_RECORDS_FILENAME, EBP_BATCH_SIZE)\n",
    "\n",
    "fmp_training_points, fmp_val_class_losses, fmp_val_normal_losses,\\\n",
    "    fmp_training_class_losses, fmp_training_normal_losses =\\\n",
    "        compile_records(FINAL_FMP_RECORDS_FILENAME, FMP_BATCH_SIZE)\n",
    "\n",
    "# Compile record compilations\n",
    "num_nbp = len(nbp_training_points)\n",
    "num_ebp = len(ebp_training_points)\n",
    "num_fmp = len(fmp_training_points)\n",
    "num_all = num_nbp + num_ebp + num_fmp\n",
    "\n",
    "total_nbp_tp = nbp_training_points[-1]\n",
    "total_ebp_tp = ebp_training_points[-1]\n",
    "\n",
    "all_training_points = np.zeros(num_all, dtype=np.int)\n",
    "all_training_points[:num_nbp] = nbp_training_points\n",
    "all_training_points[num_nbp:(num_nbp+num_ebp)] = ebp_training_points + total_nbp_tp\n",
    "all_training_points[(num_nbp+num_ebp):] = fmp_training_points + total_nbp_tp + total_ebp_tp\n",
    "\n",
    "all_val_class_losses = np.zeros(num_all)\n",
    "all_val_class_losses[:num_nbp] = nbp_val_class_losses\n",
    "all_val_class_losses[num_nbp:(num_nbp+num_ebp)] = ebp_val_class_losses\n",
    "all_val_class_losses[(num_nbp+num_ebp):] = fmp_val_class_losses\n",
    "\n",
    "all_val_normal_losses = np.zeros(num_all)\n",
    "all_val_normal_losses[:num_nbp] = nbp_val_normal_losses\n",
    "all_val_normal_losses[num_nbp:(num_nbp+num_ebp)] = ebp_val_normal_losses\n",
    "all_val_normal_losses[(num_nbp+num_ebp):] = fmp_val_normal_losses\n",
    "\n",
    "all_training_class_losses = np.zeros(num_all)\n",
    "all_training_class_losses[:num_nbp] = nbp_training_class_losses\n",
    "all_training_class_losses[num_nbp:(num_nbp+num_ebp)] = ebp_training_class_losses\n",
    "all_training_class_losses[(num_nbp+num_ebp):] = fmp_training_class_losses\n",
    "\n",
    "all_training_normal_losses = np.zeros(num_all)\n",
    "all_training_normal_losses[:num_nbp] = nbp_training_normal_losses\n",
    "all_training_normal_losses[num_nbp:(num_nbp+num_ebp)] = ebp_training_normal_losses\n",
    "all_training_normal_losses[(num_nbp+num_ebp):] = fmp_training_normal_losses\n",
    "\n",
    "all_val_total_losses = all_val_class_losses + all_val_normal_losses\n",
    "all_training_total_losses = all_training_class_losses + all_training_normal_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_training_points[num_nbp:]\n",
    "y = all_val_class_losses[num_nbp:]\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.axvline(x=total_nbp_tp+total_ebp_tp, linestyle=\"--\")\n",
    "plt.xlabel(\"Training Points Elapsed\")\n",
    "plt.ylabel(\"Validation Class Loss\")\n",
    "\n",
    "plt.savefig(\"saved_figs/val_class_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = all_training_points[num_nbp:]\n",
    "y = all_training_class_losses[num_nbp:]\n",
    "\n",
    "plt.plot(x, y, 'go')\n",
    "plt.axvline(x=total_nbp_tp+total_ebp_tp, linestyle=\"--\")\n",
    "plt.xlabel(\"Training Points Elapsed\")\n",
    "plt.ylabel(\"Training Class Loss\")\n",
    "\n",
    "plt.savefig(\"saved_figs/training_class_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = all_training_points[1:]\n",
    "y1 = all_val_normal_losses[1:]\n",
    "y2 = all_training_normal_losses[1:]\n",
    "\n",
    "plt.plot(x, y1, 'bo', label=\"Validation\")\n",
    "plt.plot(x, y2, 'go', label=\"Training\")\n",
    "plt.axvline(x=total_nbp_tp, linestyle=\"--\")\n",
    "plt.axvline(x=total_nbp_tp+total_ebp_tp, linestyle=\"--\")\n",
    "plt.xlabel(\"Training Points Elapsed\")\n",
    "plt.ylabel(\"Normal Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"saved_figs/normal_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_training_points[1:]\n",
    "y1 = all_val_total_losses[1:]\n",
    "y2 = all_training_total_losses[1:]\n",
    "\n",
    "plt.plot(all_training_points[1:], all_val_total_losses[1:], 'bo', label=\"Validation\")\n",
    "plt.plot(all_training_points[1:], all_training_total_losses[1:], 'go', label=\"Training\")\n",
    "plt.axvline(x=total_nbp_tp, linestyle=\"--\")\n",
    "plt.axvline(x=total_nbp_tp+total_ebp_tp, linestyle=\"--\")\n",
    "plt.xlabel(\"Training Points Elapsed\")\n",
    "plt.ylabel(\"Total Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"saved_figs/total_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
